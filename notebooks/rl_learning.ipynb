{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95b6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6f78e471a04392a7feb8ae65d68dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34cc3c77c7b49f59d22d0ee768c9f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05b7458083a4e428f6704697076a9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aef1c028b37468aba351fa22deddfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d17062f45a4b4fbbb4c2ae54aea485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1397 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e79982ec4544050a32270ed3787bc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/196 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38de922291e40f6859df54bdbc53278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Expert', 'Simple', 'Annotation', 'sim', 'sentence_sim', 'compression', 'expert_fk_grade', 'expert_ari', 'layman_fk_grade', 'layman_ari', 'umls_expert', 'umls_layman', 'expert_terms', 'layman_terms', 'idx'],\n",
      "        num_rows: 1397\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Expert', 'Simple', 'Annotation', 'sim', 'sentence_sim', 'compression', 'expert_fk_grade', 'expert_ari', 'layman_fk_grade', 'layman_ari', 'umls_expert', 'umls_layman', 'expert_terms', 'layman_terms', 'idx'],\n",
      "        num_rows: 196\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Expert', 'Simple', 'Annotation', 'sim', 'sentence_sim', 'compression', 'expert_fk_grade', 'expert_ari', 'layman_fk_grade', 'layman_ari', 'umls_expert', 'umls_layman', 'expert_terms', 'layman_terms', 'idx'],\n",
      "        num_rows: 300\n",
      "    })\n",
      "})\n",
      "Train sample:\n",
      " {'Expert': '75-90 % of the affected people have mild intellectual disability.', 'Simple': \"People with syndromic intellectual disabilities may have a `` typical look. ''\", 'Annotation': \"<del>75-90 % of the</del> <rep>affected people  have mild intellectual disability.<by>People with syndromic intellectual disabilities</rep> <ins>may have a `` typical look. ''</ins>\", 'sim': 0.48951049, 'sentence_sim': 0.639872432, 'compression': 1.2, 'expert_fk_grade': 12.7, 'expert_ari': 12.4, 'layman_fk_grade': 13.1, 'layman_ari': 15.1, 'umls_expert': \"[[{'start': 41, 'end': 64, 'ngram': 'intellectual disability', 'term': 'intellectual disability', 'cui': 'C3714756', 'similarity': 1.0, 'semtypes': {'T048'}, 'preferred': 1, 'preferred_term': None}, {'start': 41, 'end': 64, 'ngram': 'intellectual disability', 'term': 'Intellectual disability', 'cui': 'C3714756', 'similarity': 0.9090909090909091, 'semtypes': {'T048'}, 'preferred': 0, 'preferred_term': None}, {'start': 41, 'end': 64, 'ngram': 'intellectual disability', 'term': 'Intellectual disability, mild', 'cui': 'C0026106', 'similarity': 0.7142857142857143, 'semtypes': {'T048'}, 'preferred': 0, 'preferred_term': None}]]\", 'umls_layman': \"[[{'start': 35, 'end': 47, 'ngram': 'disabilities', 'term': 'disabilities', 'cui': 'C0231170', 'similarity': 1.0, 'semtypes': {'T033'}, 'preferred': 1, 'preferred_term': None}], [{'start': 62, 'end': 69, 'ngram': 'typical', 'term': 'Atypical', 'cui': 'C0741302', 'similarity': 0.8333333333333334, 'semtypes': {'T033'}, 'preferred': 0, 'preferred_term': None}], [{'start': 22, 'end': 34, 'ngram': 'intellectual', 'term': 'intellect', 'cui': 'C2981149', 'similarity': 0.7, 'semtypes': {'T041'}, 'preferred': 1, 'preferred_term': None}], [{'start': 12, 'end': 21, 'ngram': 'syndromic', 'term': 'Nonsyndromic', 'cui': 'C2677304', 'similarity': 0.7, 'semtypes': {'T033'}, 'preferred': 1, 'preferred_term': None}]]\", 'expert_terms': \"['intellectual disability']\", 'layman_terms': \"['disabilities', 'intellect', 'Atypical', 'Nonsyndromic']\", 'idx': 0}\n"
     ]
    }
   ],
   "source": [
    "#fine tune model on med-easi dataset with flan-t5-base to get baseline model before doing RL\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "import torch\n",
    "\n",
    "#load Med-EASi dataset\n",
    "ds = load_dataset(\"cbasu/Med-EASi\")\n",
    "print(ds)\n",
    "print(\"Train sample:\\n\", ds[\"train\"][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a30b92",
   "metadata": {},
   "source": [
    "Here, I retrain our flan-t5-base as our baseline before attempting to improve output with RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae247dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352441206ec74b1c836c0c9e998ea3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85dfbef8a14b4cee8276a2a7b01517e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f698556020a4183b5c51388975fbc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6862726d6e7442f92ce189414804220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e9d993b6f34790a4b648aa1bf65514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1397 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3da46daface40eba9654c1757e2a69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/196 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3335a945405b4f16adbc9ede5d848e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1397\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 196\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess(batch):\n",
    "    inputs = batch[\"Expert\"]\n",
    "    targets = batch[\"Simple\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        text_target=targets,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "cols_to_remove = ds[\"train\"].column_names\n",
    "\n",
    "tokenized_ds = ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=cols_to_remove,\n",
    ")\n",
    "\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f48f8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8bbefd12a047209f05e651654a08cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65fadacc251481a83b8c0510fb0e277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8fa5ee6b2b47c8b3cd56e13725e046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e890bbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msriyamed1\u001b[0m (\u001b[33msriyamed1-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251130_234616-bkvoyoxh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriyamed1-none/Med-EASE/runs/bkvoyoxh' target=\"_blank\">flan-t5-base-rl-baseline</a></strong> to <a href='https://wandb.ai/sriyamed1-none/Med-EASE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriyamed1-none/Med-EASE' target=\"_blank\">https://wandb.ai/sriyamed1-none/Med-EASE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriyamed1-none/Med-EASE/runs/bkvoyoxh' target=\"_blank\">https://wandb.ai/sriyamed1-none/Med-EASE/runs/bkvoyoxh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2813210795.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 07:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.593800</td>\n",
       "      <td>1.883344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.559400</td>\n",
       "      <td>1.832589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.470800</td>\n",
       "      <td>1.795272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.338600</td>\n",
       "      <td>1.776446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.287000</td>\n",
       "      <td>1.767708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint path: checkpoints/flan_t5_baseline/checkpoint-875\n",
      "Best metric 1.7677078247070312\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"Med-EASE\", name=\"flan-t5-base-rl-baseline\")\n",
    "\n",
    "#using best args from experiment\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"checkpoints/flan_t5_baseline\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=5,\n",
    "    warmup_steps=1000,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    tpu_num_cores=8,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "best_ckpt = trainer.state.best_model_checkpoint\n",
    "best_metric = trainer.state.best_metric\n",
    "\n",
    "print(\"Best checkpoint path:\", best_ckpt)\n",
    "print(\"Best metric\", best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0dc1475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-175\tcheckpoint-525\tcheckpoint-875\n",
      "checkpoint-350\tcheckpoint-700\truns\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/flan_t5_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c93678a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▃▂▁</td></tr><tr><td>eval/runtime</td><td>█▁▄▃▄</td></tr><tr><td>eval/samples_per_second</td><td>▁█▅▆▅</td></tr><tr><td>eval/steps_per_second</td><td>▁█▅▆▅</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▄▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▄▄▄▄▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▅▆▄▄▂▆▂▃▃▃▄▁▄▄▁▃</td></tr><tr><td>train/learning_rate</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▇▇██</td></tr><tr><td>train/loss</td><td>█▇▆▅▅▅▅▃▄▄▃▃▄▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.76771</td></tr><tr><td>eval/runtime</td><td>3.6608</td></tr><tr><td>eval/samples_per_second</td><td>53.541</td></tr><tr><td>eval/steps_per_second</td><td>6.829</td></tr><tr><td>total_flos</td><td>691261209879552.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>875</td></tr><tr><td>train/grad_norm</td><td>2.86321</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.287</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flan-t5-base-rl-baseline</strong> at: <a href='https://wandb.ai/sriyamed1-none/Med-EASE/runs/bkvoyoxh' target=\"_blank\">https://wandb.ai/sriyamed1-none/Med-EASE/runs/bkvoyoxh</a><br> View project at: <a href='https://wandb.ai/sriyamed1-none/Med-EASE' target=\"_blank\">https://wandb.ai/sriyamed1-none/Med-EASE</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251130_234616-bkvoyoxh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef3dc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4345ab457b7840ef9f8da12f51385cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_ds = ds[\"test\"]\n",
    "\n",
    "def generate_baseline(batch):\n",
    "    inputs = tokenizer(\n",
    "        batch[\"Expert\"],\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=180,\n",
    "            do_sample=False,\n",
    "        )\n",
    "\n",
    "    batch[\"pred_baseline\"] = tokenizer.batch_decode(\n",
    "        outputs, skip_special_tokens=True\n",
    "    )\n",
    "    return batch\n",
    "\n",
    "predictions_baseline = test_ds.map(\n",
    "    generate_baseline,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c0a01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacremoses) (2025.11.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sacremoses) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses) (1.5.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sacremoses) (4.67.1)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: sacremoses, portalocker, colorama, sacrebleu\n",
      "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1 sacremoses-0.1.1\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=739680695d386e35d03ffd8bc638c20754c1df35c880dd1b6fb6425e7c35e5a1\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install sacremoses sacrebleu\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbb5060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2669dd412da44ad7aa1bf871a9b2077b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d502f0e929464512b1dd3bcc1881f2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49222cb768dd42b4a9fe30b1c8de3bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01295fab72e240ea9716452d7d4deb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fb37b2270e4850802b8300a8365ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE METRICS\n",
      "SARI: {'sari': 47.23916039277024}\n",
      "BLEU: {'bleu': 0.2964113224231506, 'precisions': [0.5337995337995338, 0.3483483483483483, 0.2852233676975945, 0.2480450422270879], 'brevity_penalty': 0.8752213210898333, 'length_ratio': 0.8823956442831216, 'translation_length': 7293, 'reference_length': 8265}\n",
      "ROUGE: {'rouge1': np.float64(0.5044537619176339), 'rouge2': np.float64(0.34804808963175793), 'rougeL': np.float64(0.46862529276683085), 'rougeLsum': np.float64(0.46752514254063837)}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "sari_metric = evaluate.load(\"sari\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "sari_base = sari_metric.compute(\n",
    "    sources=predictions_baseline[\"Expert\"],\n",
    "    predictions=predictions_baseline[\"pred_baseline\"],\n",
    "    references=[[ref] for ref in predictions_baseline[\"Simple\"]],\n",
    ")\n",
    "\n",
    "bleu_base = bleu_metric.compute(\n",
    "    predictions=predictions_baseline[\"pred_baseline\"],\n",
    "    references=[[ref] for ref in predictions_baseline[\"Simple\"]],\n",
    ")\n",
    "\n",
    "rouge_base = rouge_metric.compute(\n",
    "    predictions=predictions_baseline[\"pred_baseline\"],\n",
    "    references=predictions_baseline[\"Simple\"],\n",
    ")\n",
    "\n",
    "print(\"BASELINE METRICS\")\n",
    "print(\"SARI:\", sari_base)\n",
    "print(\"BLEU:\", bleu_base)\n",
    "print(\"ROUGE:\", rouge_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "473e11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"expert\": predictions_baseline[\"Expert\"],\n",
    "    \"reference_simple\": predictions_baseline[\"Simple\"],\n",
    "    \"model_simple\": predictions_baseline[\"pred_baseline\"]\n",
    "})\n",
    "\n",
    "df.to_csv(\"model_outputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd9dd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textstat\n",
      "  Downloading textstat-0.7.11-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pyphen (from textstat)\n",
      "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (4.67.1)\n",
      "Downloading textstat-0.7.11-py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
      "Successfully installed pyphen-0.17.2 textstat-0.7.11\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97883a",
   "metadata": {},
   "source": [
    "This section of the notebook is now exploring reinforcement learning inspired ways to get output focused more on readability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a1f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import textstat\n",
    "import ast\n",
    "\n",
    "#favor outputs that have lower FKGL level \n",
    "def readability_reward(text: str, min_grade: float = 5.0, max_grade: float = 15.0) -> float:\n",
    "    \"\"\"\n",
    "    Return score between 0 and 1, where 1 = easiest to read, 0 = very hard\n",
    "    map Flesch-Kincaid grade from [min_grade, max_grade] to [1,0].\n",
    "    \"\"\"\n",
    "    grade = textstat.flesch_kincaid_grade(text)\n",
    "    if math.isnan(grade):\n",
    "        return 0.0\n",
    "\n",
    "    grade = max(min_grade, min(max_grade, grade))\n",
    "    score = 1.0 - (grade - min_grade) / (max_grade - min_grade)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a1471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_expert_terms(s: str):\n",
    "    \"\"\"\n",
    "    expert_terms is stored like \"['intellectual disability']\" within med-easi dataset.\n",
    "    parse it into a list and convert to lowercase\n",
    "    \"\"\"\n",
    "    if s is None:\n",
    "        return []\n",
    "    try:\n",
    "        terms = ast.literal_eval(s)\n",
    "        if isinstance(terms, list):\n",
    "            return [t.lower() for t in terms]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "\n",
    "def entity_reward(prediction: str, expert_terms_str: str) -> float:\n",
    "    \"\"\"\n",
    "    return fraction of expert terms present in the prediction output.\n",
    "    \"\"\"\n",
    "    terms = parse_expert_terms(expert_terms_str)\n",
    "    if not terms:\n",
    "        return 1.0\n",
    "\n",
    "    pred_lower = prediction.lower()\n",
    "    present = sum(int(term in pred_lower) for term in terms)\n",
    "    return present / len(terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94676425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#favor outputs that are less of a direct copy of expert field\n",
    "def noncopy_reward(prediction: str, expert: str) -> float:\n",
    "    \"\"\"\n",
    "    reward b/w 0 and 1, where 1 = very different from Expert field,\n",
    "    0 = identical / heavily overlapping from Expert field.\n",
    "    \"\"\"\n",
    "    pred_tokens = set(prediction.lower().split())\n",
    "    expert_tokens = set(expert.lower().split())\n",
    "    if not pred_tokens or not expert_tokens:\n",
    "        return 0.0\n",
    "    jaccard = len(pred_tokens & expert_tokens) / len(pred_tokens | expert_tokens) #use jaccard similarity\n",
    "    #high overlap ==> low reward\n",
    "    return 1.0 - jaccard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a677a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#favor outputs shorter than expert field\n",
    "def length_reward(prediction: str, expert: str) -> float:\n",
    "    \"\"\"\n",
    "    Reward b/w 0 and 1: 1 if prediction is much shorter than expert,\n",
    "    decreasing as it approaches or exceeds expert length.\n",
    "    \"\"\"\n",
    "    len_pred = len(prediction.split())\n",
    "    len_expert = len(expert.split())\n",
    "    if len_expert == 0:\n",
    "        return 0.0\n",
    "\n",
    "    ratio = len_pred / len_expert  #want this < 1 ideally\n",
    "    if ratio >= 1.0:\n",
    "        return 0.0\n",
    "    #if ratio <= 0.5 -> ~1.0, if ratio approaching 1.0 -> 0.0\n",
    "    return 1.0 - (ratio - 0.5) / 0.5 if ratio > 0.5 else 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combined_reward(prediction, expert, expert_terms_str, w_read=0.40, w_ent=0.15, w_noncopy=0.35, w_len=0.10):\n",
    "    r_read = readability_reward(prediction)\n",
    "    r_ent  = entity_reward(prediction, expert_terms_str)\n",
    "    r_nc   = noncopy_reward(prediction, expert)\n",
    "    r_len  = length_reward(prediction, expert)\n",
    "\n",
    "    return (\n",
    "        w_read * r_read +\n",
    "        w_ent  * r_ent +\n",
    "        w_noncopy * r_nc +\n",
    "        w_len * r_len\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1578bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20fa7f3f984427993e2e44dc1507c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_with_reranking(batch, num_candidates = 4):\n",
    "    experts = batch[\"Expert\"]\n",
    "    expert_terms_list = batch[\"expert_terms\"]\n",
    "\n",
    "    preds_rl = []\n",
    "\n",
    "    model.eval()\n",
    "    for expert, expert_terms_str in zip(experts, expert_terms_list):\n",
    "        inputs = tokenizer(\n",
    "            expert,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_length=256,\n",
    "                do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                temperature=1.2,\n",
    "                num_return_sequences=num_candidates,\n",
    "            )\n",
    "\n",
    "        candidates = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "        best_cand = None\n",
    "        best_reward = -1.0\n",
    "        for cand in candidates: #for each candidate, compute reward and select best candidate to use as the final prediction\n",
    "            r = combined_reward(\n",
    "                prediction=cand,\n",
    "                expert=expert,\n",
    "                expert_terms_str=expert_terms_str,\n",
    "            )\n",
    "            if r > best_reward:\n",
    "                best_reward = r\n",
    "                best_cand = cand\n",
    "\n",
    "        preds_rl.append(best_cand)\n",
    "\n",
    "    batch[\"pred_rl\"] = preds_rl\n",
    "    return batch\n",
    "\n",
    "predictions_rl = ds[\"test\"].map(\n",
    "    generate_with_reranking,\n",
    "    batched=True,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87263362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL-RERANKED METRICS\n",
      "SARI: {'sari': 36.83204616110464}\n",
      "BLEU: {'bleu': 0.12480641895779039, 'precisions': [0.39967266775777416, 0.1855421686746988, 0.13012704174228676, 0.10307101727447217], 'brevity_penalty': 0.7027876530867181, 'length_ratio': 0.7392619479733817, 'translation_length': 6110, 'reference_length': 8265}\n",
      "ROUGE: {'rouge1': np.float64(0.32887475439493924), 'rouge2': np.float64(0.16760471006347882), 'rougeL': np.float64(0.2878747139054525), 'rougeLsum': np.float64(0.2882481383411188)}\n"
     ]
    }
   ],
   "source": [
    "sari_rl = sari_metric.compute(\n",
    "    sources=predictions_rl[\"Expert\"],\n",
    "    predictions=predictions_rl[\"pred_rl\"],\n",
    "    references=[[ref] for ref in predictions_rl[\"Simple\"]],\n",
    ")\n",
    "\n",
    "bleu_rl = bleu_metric.compute(\n",
    "    predictions=predictions_rl[\"pred_rl\"],\n",
    "    references=[[ref] for ref in predictions_rl[\"Simple\"]],\n",
    ")\n",
    "\n",
    "rouge_rl = rouge_metric.compute(\n",
    "    predictions=predictions_rl[\"pred_rl\"],\n",
    "    references=predictions_rl[\"Simple\"],\n",
    ")\n",
    "\n",
    "print(\"RL-RERANKED METRICS\")\n",
    "print(\"SARI:\", sari_rl)\n",
    "print(\"BLEU:\", bleu_rl)\n",
    "print(\"ROUGE:\", rouge_rl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06b5c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"expert\": predictions_rl[\"Expert\"],\n",
    "    \"reference_simple\": predictions_rl[\"Simple\"],\n",
    "    \"model_simple\": predictions_rl[\"pred_rl\"]\n",
    "})\n",
    "\n",
    "df.to_csv(\"model_outputs_rl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f385f6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example 0 ===\n",
      "EXPERT: Intervention for obese adolescents should be focused on developing healthy eating and exercise habits rather than on losing a specific amount of weight.\n",
      "SIMPLE (ref): The treatment of adolescent obesity is focused on developing healthy eating and exercise habits rather than on losing a specific amount of weight.\n",
      "BASELINE: Intervention for obese adolescents should be focused on developing healthy eating and exercise habits rather than on losing a specific amount of weight.\n",
      "RL-RERANK: Weight loss for obese adolescents should not be about losing a particular amount of weight.\n",
      "Baseline readability: 0.0\n",
      "RL readability: 0.5073333333333331\n",
      "Baseline entity: 0.8571428571428571\n",
      "RL entity: 0.42857142857142855\n",
      "\n",
      "=== Example 1 ===\n",
      "EXPERT: The liver may be enlarged, hard, or tender; massive hepatomegaly with easily palpable nodules signifies advanced disease.\n",
      "SIMPLE (ref): Typically, the liver is enlarged and hard. It may feel tender and often lumpy.\n",
      "BASELINE: The liver may be enlarged, hard, or tender; massive hepatomegaly with easily palpable nodules signifies advanced disease.\n",
      "RL-RERANK: The liver may be enlarged, hard, or tender.\n",
      "Baseline readability: 0.244235294117647\n",
      "RL readability: 1.0\n",
      "Baseline entity: 0.8\n",
      "RL entity: 0.4\n",
      "\n",
      "=== Example 2 ===\n",
      "EXPERT: Frequency, urgency, and nocturia are due to incomplete emptying and rapid refilling of the bladder. Decreased size and force of the urinary stream cause hesitancy and intermittency. Pain and dysuria are usually not present. Sensations of incomplete emptying, terminal dribbling, overflow incontinence, or complete urinary retention may ensue.\n",
      "SIMPLE (ref): At first, men may have difficulty starting urination. Urination may also feel incomplete. Because the bladder does not empty completely, men have to urinate more frequently, often at night (nocturia).\n",
      "BASELINE: Frequency, urgency, and nocturia are due to incomplete emptying and rapid refilling of the bladder. Decreased size and force of the urinary stream cause hesitancy and intermittency. Pain and dysuria are usually not present.\n",
      "RL-RERANK: Frequency, urgency, and nocturia are due to incomplete emptying and rapid refilling of the bladder. Those symptoms include abdominal cramping and pain.\n",
      "Baseline readability: 0.4305294117647055\n",
      "RL readability: 0.4309090909090909\n",
      "Baseline entity: 0.6923076923076923\n",
      "RL entity: 0.3076923076923077\n",
      "\n",
      "=== Example 3 ===\n",
      "EXPERT: Desmopressin\n",
      "SIMPLE (ref): Sometimes, the drug desmopressin\n",
      "BASELINE: Desmopressin is a drug that is used to treat depression.\n",
      "RL-RERANK: The Desmopressin is a kind of pain medication that affects the heart.\n",
      "Baseline readability: 1.0\n",
      "RL readability: 0.9193333333333331\n",
      "Baseline entity: 0.0\n",
      "RL entity: 0.0\n",
      "\n",
      "=== Example 4 ===\n",
      "EXPERT: Some patients have weight loss, rarely enough to become underweight. Anemia, glossitis, angular stomatitis, and aphthous ulcers are usually seen in these patients.\n",
      "SIMPLE (ref): Some people are undernourished, have mild weight loss and anemia, or have mouth sores and an inflamed tongue.\n",
      "BASELINE: Some patients have weight loss, rarely enough to become underweight. Anemia, glossitis, angular stomatitis, and aphthous ulcers are usually seen in these patients.\n",
      "RL-RERANK: Some people have weight loss, that often causes them to become underweight.\n",
      "Baseline readability: 0.3018043478260868\n",
      "RL readability: 0.8209999999999997\n",
      "Baseline entity: 1.0\n",
      "RL entity: 0.3333333333333333\n",
      "\n",
      "=== Example 5 ===\n",
      "EXPERT: Involvement of the carotid and vertebral arteries results in reduced cerebral blood flow manifested by dizziness, syncope, orthostatic hypotension, headaches, transient visual disturbances, transient ischemic attacks, or strokes. Stenotic lesions in a subclavian artery near the origin of a patent vertebral artery can cause posterior circulation ischemic neurologic symptoms or syncope when the arm is used (called subclavian steal syndrome).\n",
      "SIMPLE (ref): Head: People may feel dizzy or faint, have headaches, or have problems with vision.\n",
      "BASELINE: Involvement of the carotid and vertebral arteries results in reduced cerebral blood flow, manifested by dizziness, syncope, orthostatic hypotension, headaches, transient visual disturbances, transient ischemic attacks, or strokes. Stenotic lesions in a subclavian artery near the origin of a patent vertebral artery can cause posterior circulation ischemic neurologic symptoms or syncope when the arm is used (called subclavian steal syndrome).\n",
      "RL-RERANK: Stroke can happen when the joints are sluggish, caused by pain in the cerebral system (severe vision changes), headaches, or chronic headaches. Involvement of the carotid and vertebral arteries result in lower cerebral blood flow, which often results in dizziness, syncope, orthostatic hypotension, headaches, transient visual disturbances, transient ischemic attacks, or strokes. Stenotic lesions in a subclavian artery near the origin of a patent vertebral artery can cause posterior circulation ischemic neurologic symptoms or syncope when the arm is used (called subclavian steal syndrome).\n",
      "Baseline readability: 0.0\n",
      "RL readability: 0.0\n",
      "Baseline entity: 0.92\n",
      "RL entity: 0.92\n",
      "\n",
      "=== Example 6 ===\n",
      "EXPERT: However, if the neonate 's breathing appears obstructed, suctioning is done with an endotracheal tube attached to a meconium aspirator.\n",
      "SIMPLE (ref): If the newborn 's airway seems blocked by meconium, doctors try to suction it out. Doctors used to do suctioning whenever they saw meconium in the amniotic fluid or in the newborn 's mouth, but this has not been shown to help.\n",
      "BASELINE: However, if the neonate 's breathing appears obstructed, suctioning is done with an endotracheal tube attached to a meconium aspirator.\n",
      "RL-RERANK: The mother's mother may try to remove her breath and, depending on the age and gender, suctioning the babies with a meconium aspirator.\n",
      "Baseline readability: 0.09599999999999975\n",
      "RL readability: 0.2637391304347826\n",
      "Baseline entity: 1.0\n",
      "RL entity: 0.5\n",
      "\n",
      "=== Example 7 ===\n",
      "EXPERT: Photosensitivity occurs in some patients. Lupus erythematosus tumidus is characterized by pink to violaceous urticarial nonscarring plaques and/or nodules, some annular, in light -exposed areas.\n",
      "SIMPLE (ref): Rashes resulting from exposure to sunlight (photosensitivity) occur in some people with lupus, particularly fair-skinned people.\n",
      "BASELINE: Lupus erythematosus tumidus is characterized by pink to violaceous urticarial nonscarring plaques and/or nodules, some annular, in light -exposed areas.\n",
      "RL-RERANK: Lupus erythematosus tumidus may lead to swelling or nodules in the upper and upper body. The pain may be pink, to blemished and sometimes severe.\n",
      "Baseline readability: 0.0\n",
      "RL readability: 0.7779\n",
      "Baseline entity: 0.7142857142857143\n",
      "RL entity: 0.2857142857142857\n",
      "\n",
      "=== Example 8 ===\n",
      "EXPERT: The driving force for these reactions is often the entropic benefit of gaseous evolution ( e.g.\n",
      "SIMPLE (ref): The driving force for these reactions is often the entropic benefit of releasing a gas ( e.g.\n",
      "BASELINE: The driving force for these reactions is often the entropic benefit of gaseous evolution ( e.g.\n",
      "RL-RERANK: This is the driving force for these reactions.\n",
      "Baseline readability: 0.2713333333333331\n",
      "RL readability: 1.0\n",
      "Baseline entity: 0.25\n",
      "RL entity: 0.25\n",
      "\n",
      "=== Example 9 ===\n",
      "EXPERT: Recurrence rates after surgical excision are about 5 to 15 %.\n",
      "SIMPLE (ref): After surgical removal, ganglia return in about 5 to 15 % of people.\n",
      "BASELINE: Recurrence rates after surgical excision are about 5 to 15 %.\n",
      "RL-RERANK: Recurrence rates after surgery are about 5 to 15 %, following a number of different procedures.\n",
      "Baseline readability: 0.5449999999999999\n",
      "RL readability: 0.2713333333333331\n",
      "Baseline entity: 0.3333333333333333\n",
      "RL entity: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"\\n=== Example {i} ===\")\n",
    "    print(\"EXPERT:\", predictions_rl[\"Expert\"][i])\n",
    "    print(\"SIMPLE (ref):\", predictions_rl[\"Simple\"][i])\n",
    "    print(\"BASELINE:\", predictions_baseline[\"pred_baseline\"][i])\n",
    "    print(\"RL-RERANK:\", predictions_rl[\"pred_rl\"][i])\n",
    "\n",
    "    print(\"Baseline readability:\", readability_reward(predictions_baseline[\"pred_baseline\"][i]))\n",
    "    print(\"RL readability:\", readability_reward(predictions_rl[\"pred_rl\"][i]))\n",
    "\n",
    "    print(\"Baseline entity:\", entity_reward(predictions_baseline[\"pred_baseline\"][i], predictions_rl[\"expert_terms\"][i]))\n",
    "    print(\"RL entity:\", entity_reward(predictions_rl[\"pred_rl\"][i], predictions_rl[\"expert_terms\"][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b78adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
